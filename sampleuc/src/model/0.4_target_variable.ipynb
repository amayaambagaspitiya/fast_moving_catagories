{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ece9ec-6a98-40b7-b549-04a5cfd8f76f",
   "metadata": {},
   "source": [
    "weekly sales for top 5 categories in each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1f4580-94f7-4b5f-8b64-4d6eb9f6ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_key_with_weekly_sales(primary_key_table, weekly_sales_df) :\n",
    "    \"\"\"\n",
    "    Join the primary key table with the weekly sales DataFrame and fill null values with 0.\n",
    "\n",
    "    Args:\n",
    "    - primary_key_table: DataFrame, the primary key table containing 'week', 'stg_item_category_desc_txt', and 'stg_outlet_cd' columns\n",
    "    - weekly_sales_df: DataFrame, the weekly sales data containing 'week', 'stg_item_category_desc_txt', and 'stg_outlet_cd' columns\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The resulting DataFrame after joining with weekly sales and filling null values with 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Join the primary key table with the weekly sales DataFrame\n",
    "    final_df = (\n",
    "        primary_key_table\n",
    "        .join(\n",
    "            weekly_sales_df,\n",
    "            on=[\"week\", \"stg_item_category_desc_txt\", \"stg_outlet_cd\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Fill null values with 0\n",
    "    final_df = final_df.na.fill(0)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d70f14-72ea-4098-8096-98319b4265cf",
   "metadata": {},
   "source": [
    "target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8c329f-ac0c-4798-bb48-322e7aefae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_variable(final_df):\n",
    "    \"\"\"\n",
    "    Calculates the next week's quantity for each item category and outlet.\n",
    "\n",
    "    Args:\n",
    "        final_df ): DataFrame containing the joined data\n",
    "\n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: DataFrame with an additional column \"next_week_qty\".\n",
    "    \"\"\"\n",
    "    # Define window specification\n",
    "    window_spec = Window.partitionBy(\"stg_outlet_cd\", \"stg_item_category_desc_txt\").orderBy(\"week\")\n",
    "\n",
    "    # Calculate next week's quantity\n",
    "    df_with_next_week_qty = (final_df\n",
    "                             .withColumn(\n",
    "                                 \"next_week_qty\", f.lead(\"weekly_sales_qty\").over(window_spec)))\n",
    "\n",
    "    return df_with_next_week_qty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67367b4d-f5fe-4bff-a6fe-2d9eb380e218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
